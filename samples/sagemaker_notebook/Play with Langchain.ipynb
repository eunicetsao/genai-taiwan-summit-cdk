{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a84281",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101224b2",
   "metadata": {},
   "source": [
    "## Prepare the endpoint\n",
    "\n",
    "In the previous step, you might aleady deploy a large language model for this exercise. \n",
    "\n",
    "Please copy your endpoint name here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b90ccbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'huggingface-pytorch-tgi-inference-2023-07-18-08-38-00-466'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7b263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from langchain import SQLDatabaseChain, SQLDatabase\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aade9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf97557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name= ENDPOINT_NAME,\n",
    "    region_name='us-east-1',\n",
    "    model_kwargs={\"temperature\": 0.01, \"max_new_tokens\": 200},\n",
    "    content_handler=content_handler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e570c40",
   "metadata": {},
   "source": [
    "## Get the database connection\n",
    "\n",
    "In this example, we connect to an athena database.\n",
    "\n",
    "We use the SQLAlchemy https://pypi.org/project/SQLAlchemy/ and pyathena as the connector to our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18aa2060",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATHENA_BUCKET = 'genai-text-to-sql-workshop-data7e2128ca-fxi6ydpzyhrd'\n",
    "ATHENA_DATABASE = 'genai-text-to-sql-workshop'\n",
    "ATHENA_REGION = 'us-east-1'\n",
    "conn_str = f\"awsathena+rest://:@athena.{ATHENA_REGION}.amazonaws.com:443/{ATHENA_DATABASE}?s3_staging_dir=s3://{ATHENA_BUCKET}/Unsaved/\"\n",
    "database_engine = create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10bbc343",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = SQLDatabase(database_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f701787d",
   "metadata": {},
   "source": [
    "## Try a SQLDatabaseChain\n",
    "\n",
    "A chain can be described as a wrapper that encompasses several individual components, creating a unified end-to-end process with a fixed sequence of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4a8b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "what is total sales amount of product Fruits\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT sum(price) FROM sales WHERE product = 'Fruits'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(31728.5,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m[31728.5]\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"what is total sales amount of product Fruits\"\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, data_base, verbose=True)\n",
    "\n",
    "result = db_chain(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0da2f",
   "metadata": {},
   "source": [
    "## Add Insights\n",
    "\n",
    "Sometimes, we do not only need a data, we need to know the meaning of the data. Here you can customized your own sql process and generate insights using langchian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9e4b2",
   "metadata": {},
   "source": [
    "### Creat your own SQL process\n",
    "\n",
    "You can extend the current SQLDatabaseChain to customize your own process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2b64727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "from langchain import SQLDatabaseChain, SQLDatabase, PromptTemplate, LLMChain\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.callbacks.manager import CallbackManagerForChainRun\n",
    "from langchain.chains.sql_database.base import INTERMEDIATE_STEPS_KEY\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "class SQLDatabaseChainWithInsight(SQLDatabaseChain):\n",
    "    return_intermediate_steps: bool = True\n",
    "\n",
    "    def _call(\n",
    "            self,\n",
    "            inputs: Dict[str, Any],\n",
    "            run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        _run_manager = run_manager or CallbackManagerForChainRun.get_noop_manager()\n",
    "        input_text = f\"{inputs[self.input_key]}\\nSQLQuery:\"\n",
    "        _run_manager.on_text(input_text, verbose=self.verbose)\n",
    "        # If not present, then defaults to None which is all tables.\n",
    "        table_names_to_use = inputs.get(\"table_names_to_use\")\n",
    "        table_info = self.database.get_table_info(table_names=table_names_to_use)\n",
    "        llm_inputs = {\n",
    "            \"input\": input_text,\n",
    "            \"top_k\": str(self.top_k),\n",
    "            \"dialect\": self.database.dialect,\n",
    "            \"table_info\": table_info,\n",
    "            \"stop\": [\"\\nSQLResult:\"],\n",
    "        }\n",
    "        intermediate_steps: List = []\n",
    "        try:\n",
    "            intermediate_steps.append(llm_inputs)  # input: sql generation\n",
    "            sql_cmd = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "\n",
    "            _run_manager.on_text(sql_cmd, color=\"green\", verbose=self.verbose)\n",
    "            intermediate_steps.append(\n",
    "                sql_cmd\n",
    "            )  # output: sql generation (no checker)\n",
    "            intermediate_steps.append({\"sql_cmd\": sql_cmd})  # input: sql exec\n",
    "            result = self.database.run(sql_cmd)\n",
    "            intermediate_steps.append(str(result))  # output: sql exec\n",
    "\n",
    "            _run_manager.on_text(\"\\nSQLResult: \", verbose=self.verbose)\n",
    "            _run_manager.on_text(result, color=\"yellow\", verbose=self.verbose)\n",
    "            # If return direct, we just set the final result equal to\n",
    "            # the result of the sql query result, otherwise try to get a human readable\n",
    "            # final answer\n",
    "            _run_manager.on_text(\"\\nAnswer:\", verbose=self.verbose)\n",
    "            input_text += f\"{sql_cmd}\\nSQLResult: {result}\\nAnswer:\"\n",
    "            llm_inputs[\"input\"] = input_text\n",
    "            intermediate_steps.append(llm_inputs)  # input: final answer\n",
    "            sql_data = self.llm_chain.predict(\n",
    "                callbacks=_run_manager.get_child(),\n",
    "                **llm_inputs,\n",
    "            ).strip()\n",
    "            intermediate_steps.append(sql_data)  # output: sql data\n",
    "            _run_manager.on_text(sql_data, color=\"green\", verbose=self.verbose)\n",
    "\n",
    "            GET_INSIGHT = \"\"\"\n",
    "                    You are a senior data analytics.\n",
    "\n",
    "                    Your task is to analyze the given company data in JSON format and provide insights or explanations for any trends or patterns observed. The data pertains to the question: \n",
    "                    {question}.\n",
    "                    Your response should be clear and concise, no more than 200 words.\n",
    "\n",
    "                    Response data: {data}\n",
    "\n",
    "                    Please note that if the data is empty or null, you should simply state \"no insight.\" \n",
    "\n",
    "                    My Insight:\n",
    "                    \"\"\"\n",
    "            get_insight_prompt = PromptTemplate(\n",
    "                template=GET_INSIGHT, input_variables=[\"question\", \"data\"]\n",
    "            )\n",
    "            get_insight_chain = LLMChain(\n",
    "                llm=self.llm_chain.llm, prompt=get_insight_prompt\n",
    "            )\n",
    "\n",
    "            get_insight_inputs = {\n",
    "                \"question\": inputs[self.input_key],\n",
    "                \"data\": result,\n",
    "            }\n",
    "\n",
    "            final_result: str = get_insight_chain.predict(\n",
    "                callbacks=_run_manager.get_child(), **get_insight_inputs\n",
    "            ).strip()\n",
    "\n",
    "            _run_manager.on_text(\n",
    "                final_result, color=\"blue\", verbose=self.verbose\n",
    "            )\n",
    "\n",
    "            chain_result: Dict[str, Any] = {self.output_key: final_result}\n",
    "            if self.return_intermediate_steps:\n",
    "                chain_result[INTERMEDIATE_STEPS_KEY] = intermediate_steps\n",
    "            return chain_result\n",
    "        except Exception as exc:\n",
    "            # Append intermediate steps to exception, to aid in logging and later\n",
    "            # improvement of few shot prompt seeds\n",
    "            exc.intermediate_steps = intermediate_steps  # type: ignore\n",
    "            raise exc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b1e6b",
   "metadata": {},
   "source": [
    "### Call your customized chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a6ea023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChainWithInsight chain...\u001b[0m\n",
      "what is total sales amount of product Fruits\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT sum(price) FROM sales WHERE product = 'Fruits'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(31728.5,)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m[31728.5]\u001b[0m\u001b[36;1m\u001b[1;3mThe total sales amount of product Fruits is 31728.5.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "db_chain = SQLDatabaseChainWithInsight.from_llm(llm, data_base, verbose=True)\n",
    "result = db_chain(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3055c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
